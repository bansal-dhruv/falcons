{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ayush-bansal/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ayush-bansal/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ayush-bansal/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ayush-bansal/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ayush-bansal/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ayush-bansal/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras imported\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.applications.resnet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d48209088ee9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minception_v3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInceptionV3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minception_resnet_v2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInceptionResNetV2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Models imported\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.applications.resnet'"
     ]
    }
   ],
   "source": [
    "# Keras' imports\n",
    "from keras import models, layers, optimizers\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Lambda, MaxPool2D\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta, RMSprop\n",
    "from keras.models import Model, Sequential, model_from_json\n",
    "print(\"Keras imported\")\n",
    "\n",
    "# Pre-trained models\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.resnet import ResNet50\n",
    "print(\"Models imported\")\n",
    "\n",
    "# Callbacks\n",
    "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# Sklearn's imports\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, learning_curve, KFold, cross_val_score, StratifiedKFold\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve, auc\n",
    "print(\"Sklearn imported\")\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import zlib\n",
    "import itertools\n",
    "import sklearn\n",
    "import scipy\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "print(\"All libraries imported sucessfully!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "path = '/content/drive'\n",
    "drive.mount(path, force_remount=True)\n",
    "\n",
    "root = path + '/My Drive/'\n",
    "train_dir = root + \"Train/\"\n",
    "test_dir =  root + \"Test/\"\n",
    "\n",
    "Vgg16_notop        = root + 'vgg16_notop.h5'\n",
    "Xception_notop     = root + 'xception_notop.h5'\n",
    "Inception_v2_notop = root + 'Weights/inception_resnet_v2_notop.h5'\n",
    "Inception_v3_notop = root + 'inception_v3_notop.h5'\n",
    "Resnet50_notop     = root + 'resnet50_notop.h5'\n",
    "\n",
    "Xception_top       = root + 'xception_top.h5'\n",
    "Inception_v2_top   = root + 'inception_resnet_v2_top.h5'\n",
    "Inception_v3_top   = root + 'inception_v3_top.h5'\n",
    "Resnet50_top       = root + 'resnet50_top.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_characters = {}\n",
    "imageSize = 60\n",
    "\n",
    "def get_data(folder):\n",
    "    # Load the data and classifing labels from the given folder.\n",
    "    X = []\n",
    "    y = []\n",
    "    for folderName in os.listdir(folder):\n",
    "        folderName = folderName.split(\"_\")[0]\n",
    "        \n",
    "        # finding label for a image\n",
    "        if folderName == 'del':\n",
    "            label = 27\n",
    "        elif folderName == 'nothing':\n",
    "            label = 29\n",
    "        elif folderName == 'spacebar':\n",
    "            label = 28           \n",
    "        elif len(folderName) == 1:\n",
    "            label = ord(folderName) - 64\n",
    "        \n",
    "        # reading name of images \n",
    "        if folder.endswith(\"test/\"):\n",
    "            image_filenames = [folder + folderName + \"_test.jpg\"]\n",
    "        else:\n",
    "            map_characters[label] = folderName\n",
    "            image_filenames = os.listdir(folder + folderName)\n",
    "        \n",
    "        # Making image vector\n",
    "        for image_filename in image_filenames:\n",
    "            img_file = cv2.imread(folder + folderName + '/' + image_filename)\n",
    "            img_file = skimage.transform.resize(img_file, (imageSize, imageSize, 3))\n",
    "            img_arr = np.asarray(img_file)\n",
    "            X.append(img_arr)\n",
    "            y.append(label)\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    return X, y\n",
    "X_train, y_train = get_data(train_dir)\n",
    "#X_test, y_test= get_data(test_dir) # Too few images\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.25) \n",
    "\n",
    "# Encode labels to hot vectors\n",
    "y_trainHot = to_categorical(y_train, num_classes = 30)\n",
    "y_testHot = to_categorical(y_test, num_classes = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data to permit further subsampling\n",
    "# Max Value can be 87000 = 29 * 3000[(no. of classes) * (no of images)]\n",
    "sample_size = 2397\n",
    "X_train, y_trainHot = shuffle(X_train, y_trainHot, random_state = 2397)\n",
    "X_test, y_testHot = shuffle(X_test, y_testHot, random_state = 2397)\n",
    "\n",
    "X_train = X_train[ : sample_size]\n",
    "X_test = X_test[ : sample_size]\n",
    "y_trainHot = y_trainHot[ : sample_size]\n",
    "y_testHot = y_testHot[ : sample_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions Learning Curves and Confusion Matrix\n",
    "class MetricsCheckpoint(Callback):\n",
    "    \"\"\"Callback that saves metrics after each epoch\"\"\"\n",
    "    def __init__(self, savepath):\n",
    "        super(MetricsCheckpoint, self).__init__()\n",
    "        self.savepath = savepath\n",
    "        self.history = {}\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        np.save(self.savepath, self.history)\n",
    "\n",
    "def plotKerasLearningCurve():\n",
    "    plt.figure(figsize=(10,5))\n",
    "    metrics = np.load('logs.npy')[()]\n",
    "    filt = ['acc'] \n",
    "    # try to add 'loss' to see the loss learning curve\n",
    "    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n",
    "        l = np.array(metrics[k])\n",
    "        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n",
    "        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n",
    "        y = l[x]\n",
    "        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n",
    "        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n",
    "    plt.legend(loc=4)\n",
    "    plt.axis([0, None, None, None]);\n",
    "    plt.grid()\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize = False, title = 'Confusion matrix', cmap = plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize = (8,8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def plot_learning_curve(history):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig(root + 'plots/accuracy_curve.png')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig(root + 'plots/loss_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topless_Network(data, pretrainedmodel, pretrainedweights, classweight, optimizer, labels):\n",
    "    xtrain, ytrain, xtest, ytest = data\n",
    "    base_model = pretrainedmodel\n",
    "    \n",
    "    # Add top layer\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    predictions = Dense(30, activation='softmax')(x)\n",
    "    model = Model(inputs = base_model.input, outputs = predictions)\n",
    "    \n",
    "    # Train top layer\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics=['accuracy'])\n",
    "    callbacks_list = [EarlyStopping(monitor = 'val_acc', patience = 3, verbose = 1)]\n",
    "    model.summary()\n",
    "    \n",
    "    # Fit model\n",
    "    history = model.fit(xtrain, ytrain, \n",
    "                        epochs = 10, \n",
    "                        class_weight = classweight, \n",
    "                        validation_data = (xtest, ytest), \n",
    "                        verbose = 1, \n",
    "                        callbacks = [MetricsCheckpoint(root + 'logs')])\n",
    "    \n",
    "    # Evaluate model\n",
    "    score = model.evaluate(xtest, ytest, verbose = 0)\n",
    "    print('\\nKeras CNN - accuracy:', score[1], '\\n')\n",
    "    y_pred = model.predict(xtest)\n",
    "    class_report = classification_report(np.where(ytest > 0)[1], \n",
    "                                         np.argmax(y_pred, axis=1), \n",
    "                                         target_names = list(labels.values()))\n",
    "    print('\\n', class_report. sep = \"\") \n",
    "    Y_pred_classes = np.argmax(y_pred,axis = 1) \n",
    "    Y_true = np.argmax(ytest, axis = 1) \n",
    "    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "    \n",
    "    # Ploting results\n",
    "    plotKerasLearningCurve()\n",
    "    plt.show()\n",
    "    plot_learning_curve(history)\n",
    "    plt.show()\n",
    "    plot_confusion_matrix(confusion_mtx, classes = list(labels.values()))\n",
    "    plt.show()\n",
    "    return model\n",
    "\n",
    "# Weights\n",
    "class_weight1 = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "\n",
    "# Pre-Trained model\n",
    "model_1 = VGG16(weights = Vgg16_notop, \n",
    "                include_top = False, \n",
    "                input_shape = (imageSize, imageSize, 3))\n",
    "\n",
    "model_2 = InceptionV3(weights = Inception_v3_notop, \n",
    "                      include_top = False, \n",
    "                      input_shape = (imageSize, imageSize, 3))\n",
    "\n",
    "model_3 = Xception(weights = Xception_notop, \n",
    "                   include_top = False, \n",
    "                   input_shape = (imageSize, imageSize, 3))\n",
    "\n",
    "model_4 = InceptionResNetV2(weights = Inception_v2_notop, \n",
    "                            include_top = False, \n",
    "                            input_shape = (imageSize, imageSize, 3))\n",
    "\n",
    "model_5 = ResNet50(weights = Resnet50_notop, \n",
    "                   include_top = False, \n",
    "                   input_shape = (imageSize, imageSize, 3))\n",
    "\n",
    "# Optimizer\n",
    "optimizer1 = Adam()\n",
    "optimizer2 = RMSprop(lr = 0.0001)\n",
    "\n",
    "# Data\n",
    "data = (X_train, y_trainHot, X_test, y_testHot)\n",
    "\n",
    "topless_Network(data, model_1, weight_path1, class_weight1, optimizer1, map_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_Network(data, pretrainedmodel, pretrainedweights, classweight, optimizer, labels):\n",
    "    xtrain, ytrain, xtest, ytest = data\n",
    "    base_model = pretrainedmodel\n",
    "    predictions = Dense(30, activation='softmax')(x)\n",
    "    model = Model(inputs = base_model.input, outputs = predictions)\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics=['accuracy'])\n",
    "    callbacks_list = [EarlyStopping(monitor = 'val_acc', patience = 3, verbose = 1)]\n",
    "    model.summary()\n",
    "    \n",
    "    # Fit model\n",
    "    history = model.fit(xtrain, ytrain, \n",
    "                        epochs = 10, \n",
    "                        class_weight = classweight, \n",
    "                        validation_data = (xtest, ytest), \n",
    "                        verbose = 1, \n",
    "                        callbacks = [MetricsCheckpoint(root + 'logs')])\n",
    "    \n",
    "    # Evaluate model\n",
    "    score = model.evaluate(xtest, ytest, verbose = 0)\n",
    "    print('\\nKeras CNN - accuracy:', score[1], '\\n')\n",
    "    y_pred = model.predict(xtest)\n",
    "    class_report = classification_report(np.where(ytest > 0)[1], \n",
    "                                         np.argmax(y_pred, axis=1), \n",
    "                                         target_names = list(labels.values()))\n",
    "    print('\\n', class_report. sep = \"\") \n",
    "    Y_pred_classes = np.argmax(y_pred,axis = 1) \n",
    "    Y_true = np.argmax(ytest, axis = 1) \n",
    "    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "    \n",
    "    # Ploting results\n",
    "    plotKerasLearningCurve()\n",
    "    plt.show()\n",
    "    plot_learning_curve(history)\n",
    "    plt.show()\n",
    "    plot_confusion_matrix(confusion_mtx, classes = list(labels.values()))\n",
    "    plt.show()\n",
    "    return model\n",
    "\n",
    "# Weights\n",
    "class_weight1 = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "\n",
    "# Pre-Trained model\n",
    "model_1 = VGG16(weights = Vgg16_notop, \n",
    "                include_top = True, \n",
    "                input_shape = (imageSize, imageSize, 3),\n",
    "                classes = 30)\n",
    "\n",
    "model_2 = InceptionV3(weights = Inception_v3_notop, \n",
    "                      include_top = True, \n",
    "                      input_shape = (imageSize, imageSize, 3),\n",
    "                      classes = 30)\n",
    "\n",
    "model_3 = Xception(weights = Xception_notop, \n",
    "                   include_top = True, \n",
    "                   input_shape = (imageSize, imageSize, 3),\n",
    "                   classes = 30)\n",
    "\n",
    "model_4 = InceptionResNetV2(weights = Inception_v2_notop, \n",
    "                            include_top = True, \n",
    "                            input_shape = (imageSize, imageSize, 3),\n",
    "                            classes = 30)\n",
    "\n",
    "model_5 = ResNet50(weights = Resnet50_notop, \n",
    "                   include_top = True, \n",
    "                   input_shape = (imageSize, imageSize, 3), \n",
    "                   classes = 30)\n",
    "\n",
    "# Optimizer\n",
    "optimizer1 = Adam()\n",
    "optimizer2 = RMSprop(lr = 0.0001)\n",
    "\n",
    "# Data\n",
    "data = (X_train, y_trainHot, X_test, y_testHot)\n",
    "\n",
    "model_Network(data, model_1, weight_path1, class_weight1, optimizer1, map_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
